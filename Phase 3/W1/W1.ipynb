{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOWV4+YbpW+apRyYScE9x2b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WeQScpUctxRY","executionInfo":{"status":"ok","timestamp":1746969321575,"user_tz":-480,"elapsed":20810,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}},"outputId":"15b3de71-a554-45a5-831c-d8d0e35270aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","FOLDERNAME = \"Colab\\ Notebooks/WeHelp/\""]},{"cell_type":"code","source":["%cd drive/MyDrive/$FOLDERNAME"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1KSOzu2uEXk","executionInfo":{"status":"ok","timestamp":1746969322434,"user_tz":-480,"elapsed":859,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}},"outputId":"c66e5233-aa7e-4bc6-91f0-7c888f34fdda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/WeHelp\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.datasets import ImageFolder\n","from PIL import Image\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"lkXLVG4hIdVr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","  device = torch.device('cuda')\n","else:\n","  device = torch.device('cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WeV-foRAuOmf","executionInfo":{"status":"ok","timestamp":1746969333550,"user_tz":-480,"elapsed":9,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}},"outputId":"a229f110-7fca-4414-9e6b-bb22bb57016b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["# Paths to the data directories\n","data_dir = 'data/handwriting/'\n","augmented_images_dir = os.path.join(data_dir, 'augmented_images/augmented_images1')\n","combined_test_dir = os.path.join(data_dir, 'handwritten-english-characters-and-digits/combined_folder/test')"],"metadata":{"id":"FSP2QIzdIleV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SIZE = 28\n","transform = T.Compose([\n","    T.Resize((SIZE, SIZE)),\n","    T.ToTensor(),\n","    T.Grayscale(num_output_channels=1),\n","    T.Normalize((0.5,), (0.5,))\n","])"],"metadata":{"id":"dhUYeK9guRbA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH = 32\n","train_data = ImageFolder(augmented_images_dir, transform=transform)\n","val_data = ImageFolder(combined_test_dir, transform=transform)\n","\n","mini_trains = DataLoader(train_data, batch_size=BATCH, shuffle=True, num_workers=4)\n","mini_vals = DataLoader(val_data, batch_size=BATCH, num_workers=4)\n","\n","NUM_TRAIN = len(train_data)\n","NUM_VAL = len(val_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4mHeb6Ew9jF","executionInfo":{"status":"ok","timestamp":1746969349210,"user_tz":-480,"elapsed":15657,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}},"outputId":"ccbf264f-36c3-4264-d088-59fa754830cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["model = nn.Sequential(\n","    # N x 1 x 28 x 28\n","    nn.Conv2d(1, 32, 3, 1, 1),\n","    nn.BatchNorm2d(32),\n","    nn.ReLU(),\n","    nn.MaxPool2d(2, 2),  # N x 32 x 14 x 14\n","\n","    nn.Conv2d(32, 64, 3, 1, 1),\n","    nn.BatchNorm2d(64),\n","    nn.ReLU(),\n","    nn.MaxPool2d(2, 2),  # N x 64 x 7 x 7\n","\n","    nn.Conv2d(64, 128, 3, 1, 1),\n","    nn.BatchNorm2d(128),\n","    nn.ReLU(),\n","    nn.MaxPool2d(2, 2),  # N x 128 x 3 x 3\n","\n","    nn.Flatten(),\n","    nn.Linear(128 * 3 * 3, 512),\n","    nn.ReLU(),\n","    nn.Linear(512, 62)\n",")\n","model = model.to(device)"],"metadata":{"id":"wimRiS_BLTkZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_function = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","NUM_EPOCH = 3\n","PRINT_EVERY = 20"],"metadata":{"id":"23yuSwKSLhmN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def val(mini_vals, model, device):\n","  model.eval()\n","  with torch.no_grad():\n","    total = 0\n","    for x, y in mini_vals:\n","      x = x.to(device)\n","      y = y.to(device)\n","      scores = model(x)\n","      predictions = scores.argmax(axis=1)\n","      acc = predictions.eq(y).sum().item()\n","      total += acc\n","    print(\"Total Acc:\", total / NUM_VAL)"],"metadata":{"id":"Zp5ZZkyjLnf2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(mini_trains, model, loss_function, optimizer, device, mini_vals):\n","  for epoch in range(NUM_EPOCH):\n","    count = 0\n","    for count, (x, y) in enumerate(mini_trains):\n","      model.train()\n","      x = x.to(device)\n","      y = y.to(device)\n","      scores = model(x)\n","      loss = loss_function(scores, y)\n","      if count % PRINT_EVERY == 0:\n","        print('Training Loss:', loss.item(), end=' / ')\n","        val(mini_vals, model, device)\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()"],"metadata":{"id":"GKspL8J6MKZF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(mini_trains, model, loss_function, optimizer, device, mini_vals)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ra53i73JMOWT","executionInfo":{"status":"ok","timestamp":1746971692949,"user_tz":-480,"elapsed":2343588,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}},"outputId":"9860a327-2558-4afa-b992-bfbd89e3321c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Loss: 4.229940414428711 / Total Acc: 0.016129032258064516\n","Training Loss: 4.1727776527404785 / Total Acc: 0.021994134897360705\n","Training Loss: 4.047776222229004 / Total Acc: 0.05571847507331378\n","Training Loss: 3.894242525100708 / Total Acc: 0.04838709677419355\n","Training Loss: 4.036081790924072 / Total Acc: 0.06744868035190615\n","Training Loss: 3.8439884185791016 / Total Acc: 0.0689149560117302\n","Training Loss: 3.328083038330078 / Total Acc: 0.17008797653958943\n","Training Loss: 3.317216634750366 / Total Acc: 0.22287390029325513\n","Training Loss: 2.92086124420166 / Total Acc: 0.14809384164222875\n","Training Loss: 2.6082441806793213 / Total Acc: 0.2727272727272727\n","Training Loss: 2.7096822261810303 / Total Acc: 0.35043988269794724\n","Training Loss: 2.108665943145752 / Total Acc: 0.43255131964809385\n","Training Loss: 1.822569727897644 / Total Acc: 0.46187683284457476\n","Training Loss: 1.9072309732437134 / Total Acc: 0.533724340175953\n","Training Loss: 1.2989475727081299 / Total Acc: 0.5894428152492669\n","Training Loss: 1.832822322845459 / Total Acc: 0.5909090909090909\n","Training Loss: 1.7740976810455322 / Total Acc: 0.5953079178885631\n","Training Loss: 1.4964725971221924 / Total Acc: 0.5278592375366569\n","Training Loss: 1.4143149852752686 / Total Acc: 0.7243401759530792\n","Training Loss: 1.576128602027893 / Total Acc: 0.6671554252199413\n","Training Loss: 1.1930201053619385 / Total Acc: 0.656891495601173\n","Training Loss: 1.3880432844161987 / Total Acc: 0.6671554252199413\n","Training Loss: 1.1770355701446533 / Total Acc: 0.6847507331378299\n","Training Loss: 1.224280834197998 / Total Acc: 0.6979472140762464\n","Training Loss: 1.2536357641220093 / Total Acc: 0.658357771260997\n","Training Loss: 1.2931864261627197 / Total Acc: 0.6539589442815249\n","Training Loss: 1.3051178455352783 / Total Acc: 0.6935483870967742\n","Training Loss: 0.7389780282974243 / Total Acc: 0.7228739002932552\n","Training Loss: 0.7288116216659546 / Total Acc: 0.718475073313783\n","Training Loss: 0.7621399164199829 / Total Acc: 0.6818181818181818\n","Training Loss: 1.1447445154190063 / Total Acc: 0.7463343108504399\n","Training Loss: 0.9850462079048157 / Total Acc: 0.6627565982404692\n","Training Loss: 1.0831269025802612 / Total Acc: 0.7712609970674487\n","Training Loss: 0.6465660929679871 / Total Acc: 0.7712609970674487\n","Training Loss: 0.7680884599685669 / Total Acc: 0.7463343108504399\n","Training Loss: 0.8568150401115417 / Total Acc: 0.7375366568914956\n","Training Loss: 0.7497381567955017 / Total Acc: 0.7741935483870968\n","Training Loss: 0.776648998260498 / Total Acc: 0.717008797653959\n","Training Loss: 0.7913978695869446 / Total Acc: 0.7683284457478006\n","Training Loss: 0.6989770531654358 / Total Acc: 0.7595307917888563\n","Training Loss: 0.7208971381187439 / Total Acc: 0.7565982404692082\n","Training Loss: 0.7440671324729919 / Total Acc: 0.7683284457478006\n","Training Loss: 0.8569780588150024 / Total Acc: 0.7668621700879765\n","Training Loss: 0.4301120936870575 / Total Acc: 0.7683284457478006\n","Training Loss: 0.39016634225845337 / Total Acc: 0.781524926686217\n","Training Loss: 0.8802332282066345 / Total Acc: 0.7316715542521994\n","Training Loss: 0.7485231757164001 / Total Acc: 0.782991202346041\n","Training Loss: 0.6629800796508789 / Total Acc: 0.782991202346041\n","Training Loss: 1.024674892425537 / Total Acc: 0.7888563049853372\n","Training Loss: 0.6045868992805481 / Total Acc: 0.7859237536656891\n","Training Loss: 0.4036172926425934 / Total Acc: 0.8020527859237536\n","Training Loss: 0.6125447750091553 / Total Acc: 0.8079178885630498\n","Training Loss: 0.5672705173492432 / Total Acc: 0.8020527859237536\n","Training Loss: 0.3471560478210449 / Total Acc: 0.7609970674486803\n","Training Loss: 0.3285982608795166 / Total Acc: 0.7785923753665689\n","Training Loss: 1.0767490863800049 / Total Acc: 0.7917888563049853\n","Training Loss: 0.3379356265068054 / Total Acc: 0.7873900293255132\n","Training Loss: 0.6862430572509766 / Total Acc: 0.8020527859237536\n","Training Loss: 0.556043267250061 / Total Acc: 0.7859237536656891\n","Training Loss: 0.4923792779445648 / Total Acc: 0.781524926686217\n","Training Loss: 0.39010363817214966 / Total Acc: 0.7785923753665689\n","Training Loss: 0.6481530070304871 / Total Acc: 0.7961876832844574\n","Training Loss: 0.5580651760101318 / Total Acc: 0.7844574780058651\n","Training Loss: 0.6028459668159485 / Total Acc: 0.7903225806451613\n","Training Loss: 1.0231069326400757 / Total Acc: 0.7903225806451613\n","Training Loss: 0.5074540376663208 / Total Acc: 0.7917888563049853\n"]}]}]}