{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMY1GFNTs8aKvg4WbSp7O8M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pFG-JwLxQL2Z","executionInfo":{"status":"ok","timestamp":1747564864406,"user_tz":-480,"elapsed":5317,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}},"outputId":"c88827a4-4720-43d0-e7bb-8fd6aae7dadf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","FOLDERNAME = \"Colab\\ Notebooks/WeHelp/\""]},{"cell_type":"code","source":["%cd drive/MyDrive/$FOLDERNAME"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Md-i_-yQR0B","executionInfo":{"status":"ok","timestamp":1747564864414,"user_tz":-480,"elapsed":6,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}},"outputId":"6174f2ea-a169-480e-a190-aa1d54dbf1e6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/WeHelp\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torchvision\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.transforms import functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.io import read_image\n","from torchvision.utils import draw_bounding_boxes\n","import matplotlib.pyplot as plt\n","import random\n","import ast"],"metadata":{"id":"fW2VaEljR7cX","executionInfo":{"status":"ok","timestamp":1747564867524,"user_tz":-480,"elapsed":3109,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["path = 'data/vehicles_images/'\n","train = os.path.join(path, \"train\")\n","test = os.path.join(path, \"test\")\n","category = os.path.join(path, \"category.txt\")\n","train_labels = os.path.join(path, \"train_labels.csv\")\n","test_labels = os.path.join(path, \"test_labels.csv\")\n","output_path = os.path.join(path, \"output\")\n","checkpoint = os.path.join(path, \"best_model.pth\")\n","os.makedirs(output_path, exist_ok=True)"],"metadata":{"id":"muHlCOPFUGNP","executionInfo":{"status":"ok","timestamp":1747564867527,"user_tz":-480,"elapsed":0,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["category_dict = None\n","with open(category, 'r') as f:\n","  line = f.read().strip()\n","  if ':' in line:\n","    categories_str = line.split(\":\", 1)[1].strip()\n","    category_dict = ast.literal_eval(categories_str)\n","classes = [None] * len(category_dict)\n","for k, v in category_dict.items():\n","  classes[v] = k"],"metadata":{"id":"fsME72vOVufL","executionInfo":{"status":"ok","timestamp":1747564867529,"user_tz":-480,"elapsed":1,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["category_dict"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-c6kO8rXvh6o","executionInfo":{"status":"ok","timestamp":1747564867534,"user_tz":-480,"elapsed":4,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}},"outputId":"f83fa6a5-dbf7-44e2-dc34-af3eaf2cf25a"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Bus': 0, 'Car': 1, 'Motorcycle': 2, 'Pickup': 3, 'Truck': 4}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Custom dataset\n","class VehicleDataset(Dataset):\n","  def __init__(self, img_dir, label_csv, transforms=None):\n","    self.img_dir = img_dir\n","    self.df = pd.read_csv(label_csv)\n","    self.imgs = self.df['filename'].unique().tolist()\n","    self.transforms = transforms\n","\n","  def __getitem__(self, idx):\n","    filename = self.imgs[idx]\n","    img_path = os.path.join(self.img_dir, filename)\n","    image = read_image(img_path).float() / 255.0  # Normalize to [0, 1]\n","    records = self.df[self.df['filename'] == filename]\n","    boxes = records[['xmin', 'ymin', 'xmax', 'ymax']].values\n","    labels = records['class'].apply(lambda x: category_dict[x]).values\n","    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n","    labels = torch.as_tensor(labels, dtype=torch.int64)\n","    target = {\"boxes\": boxes, \"labels\": labels, \"image_id\": torch.tensor([idx])}\n","    if self.transforms:\n","      image = self.transforms(image)\n","    return image, target\n","\n","  def __len__(self):\n","    return len(self.imgs)"],"metadata":{"id":"mXOUmJDhE-Nv","executionInfo":{"status":"ok","timestamp":1747564867535,"user_tz":-480,"elapsed":0,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Load pretrained faster R-CNN\n","num_classes = len(category_dict)\n","weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n","transform = weights.transforms()\n","model = fasterrcnn_resnet50_fpn(weights=weights)\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","# Enable backbone fine-tuning\n","for name, param in model.backbone.body.named_parameters():\n","    param.requires_grad = True\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2RRl1Y40y3T7","executionInfo":{"status":"ok","timestamp":1747564868367,"user_tz":-480,"elapsed":831,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}},"outputId":"e1fee2fe-d5a8-4b2e-ca42-2afbe5e0bc78"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FasterRCNN(\n","  (transform): GeneralizedRCNNTransform(\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","  )\n","  (backbone): BackboneWithFPN(\n","    (body): IntermediateLayerGetter(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): FrozenBatchNorm2d(256, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(512, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(1024, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(2048, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (fpn): FeaturePyramidNetwork(\n","      (inner_blocks): ModuleList(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","      )\n","      (layer_blocks): ModuleList(\n","        (0-3): 4 x Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","      (extra_blocks): LastLevelMaxPool()\n","    )\n","  )\n","  (rpn): RegionProposalNetwork(\n","    (anchor_generator): AnchorGenerator()\n","    (head): RPNHead(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","      )\n","      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): RoIHeads(\n","    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n","    (box_head): TwoMLPHead(\n","      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (box_predictor): FastRCNNPredictor(\n","      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Load datasets\n","train_dataset = VehicleDataset(train, train_labels, transforms=transform)\n","test_dataset = VehicleDataset(test, test_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"],"metadata":{"id":"N5KTR3Rrp1kw","executionInfo":{"status":"ok","timestamp":1747564868381,"user_tz":-480,"elapsed":11,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)"],"metadata":{"id":"6_8wCPhruUct","executionInfo":{"status":"ok","timestamp":1747564868388,"user_tz":-480,"elapsed":2,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Training\n","def train_one_epoch(epoch):\n","  model.train()\n","  for imgs, targets in train_loader:\n","    imgs = [img.to(device) for img in imgs]\n","    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","    loss_dict = model(imgs, targets)\n","    losses = sum(loss for loss in loss_dict.values())\n","\n","    optimizer.zero_grad()\n","    losses.backward()\n","    optimizer.step()\n","\n","  print(f\"[Epoch {epoch}] Loss: {losses.item():.4f}\")"],"metadata":{"id":"PzBIKnsnuVVw","executionInfo":{"status":"ok","timestamp":1747564868395,"user_tz":-480,"elapsed":5,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Evaluation Function\n","def evaluate_model():\n","  model.eval()\n","  total_score = 0.0\n","  total_objects = 0\n","\n","  with torch.no_grad():\n","    for imgs, _ in test_loader:\n","      imgs = [img.to(device) for img in imgs]\n","      outputs = model(imgs)\n","\n","      for output in outputs:\n","        scores = output['scores'].cpu()\n","        if len(scores) > 0:\n","          total_score += scores.sum().item()\n","          total_objects += len(scores)\n","\n","  average_score = total_score / total_objects if total_objects > 0 else 0.0\n","  return average_score"],"metadata":{"id":"cJrnyY9uuf-G","executionInfo":{"status":"ok","timestamp":1747564868429,"user_tz":-480,"elapsed":33,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class_color_map = {\n","  classes[0]: \"red\",\n","  classes[1]: \"green\",\n","  classes[2]: \"blue\",\n","  classes[3]: \"yellow\",\n","  classes[4]: \"magenta\"\n","}"],"metadata":{"id":"aFXMoWrz97_y","executionInfo":{"status":"ok","timestamp":1747564868431,"user_tz":-480,"elapsed":1,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Save predictions on sample images\n","def save_predictions(n=2):\n","  model.eval()\n","  count = 0\n","\n","  with torch.no_grad():\n","    for imgs, _ in test_loader:\n","      imgs = [img.to(device) for img in imgs]\n","      outputs = model(imgs)\n","\n","      for img_tensor, output in zip(imgs, outputs):\n","        img = img_tensor.cpu()\n","        boxes = output['boxes'].cpu()\n","        scores = output['scores'].cpu()\n","        labels_idx = output['labels'].cpu()\n","        keep = scores > 0.6\n","        boxes = boxes[keep]\n","        labels_idx = labels_idx[keep]\n","        labels = [classes[i] for i in labels_idx]\n","        colors = [class_color_map.get(label, \"white\") for label in labels]\n","        if len(boxes) == 0:\n","          continue\n","        img = (img * 255).byte()\n","        drawn = draw_bounding_boxes(img, boxes, labels=labels, colors=colors, width=3)\n","        img_np = F.to_pil_image(drawn)\n","\n","        out_path = os.path.join(output_path, f\"prediction_{count}.png\")\n","        img_np.save(out_path)\n","        print(f\"Saved: {out_path}\")\n","        count += 1\n","        if count >= n:\n","          return"],"metadata":{"id":"LYXoBzUn43a1","executionInfo":{"status":"ok","timestamp":1747564868434,"user_tz":-480,"elapsed":1,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["num_epochs = 50\n","best_score = 0\n","\n","for epoch in range(num_epochs):\n","  train_one_epoch(epoch)\n","  avg_score = evaluate_model()\n","\n","  # Save best model\n","  if avg_score > best_score:\n","    best_score = avg_score\n","    torch.save(model.state_dict(), checkpoint)\n","\n","print(f\"\\nBest average score: {best_score:.2%}\")\n","\n","if best_score > 0.6:\n","  save_predictions(n=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pATOwcM_w19S","executionInfo":{"status":"ok","timestamp":1747565200898,"user_tz":-480,"elapsed":332463,"user":{"displayName":"王廣瑜","userId":"13649321363543885870"}},"outputId":"6ee6bbe8-6db8-4d3f-be3a-b405103728b3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[Epoch 0] Loss: 1.0101\n","[Epoch 1] Loss: 0.6442\n","[Epoch 2] Loss: 0.5428\n","[Epoch 3] Loss: 0.4343\n","[Epoch 4] Loss: 0.2934\n","[Epoch 5] Loss: 0.4297\n","[Epoch 6] Loss: 0.4842\n","[Epoch 7] Loss: 0.2937\n","[Epoch 8] Loss: 0.3674\n","[Epoch 9] Loss: 0.2955\n","[Epoch 10] Loss: 0.2951\n","[Epoch 11] Loss: 0.2535\n","[Epoch 12] Loss: 0.4072\n","[Epoch 13] Loss: 0.3749\n","[Epoch 14] Loss: 0.1482\n","[Epoch 15] Loss: 0.2748\n","[Epoch 16] Loss: 0.2974\n","[Epoch 17] Loss: 0.3093\n","[Epoch 18] Loss: 0.3428\n","[Epoch 19] Loss: 0.2721\n","[Epoch 20] Loss: 0.2154\n","[Epoch 21] Loss: 0.2870\n","[Epoch 22] Loss: 0.3057\n","[Epoch 23] Loss: 0.1749\n","[Epoch 24] Loss: 0.2286\n","[Epoch 25] Loss: 0.2805\n","[Epoch 26] Loss: 0.2907\n","[Epoch 27] Loss: 0.2452\n","[Epoch 28] Loss: 0.1114\n","[Epoch 29] Loss: 0.1705\n","[Epoch 30] Loss: 0.2452\n","[Epoch 31] Loss: 0.0808\n","[Epoch 32] Loss: 0.2770\n","[Epoch 33] Loss: 0.1695\n","[Epoch 34] Loss: 0.2148\n","[Epoch 35] Loss: 0.2036\n","[Epoch 36] Loss: 0.2225\n","[Epoch 37] Loss: 0.1395\n","[Epoch 38] Loss: 0.1837\n","[Epoch 39] Loss: 0.1699\n","[Epoch 40] Loss: 0.2084\n","[Epoch 41] Loss: 0.0923\n","[Epoch 42] Loss: 0.1182\n","[Epoch 43] Loss: 0.2399\n","[Epoch 44] Loss: 0.1705\n","[Epoch 45] Loss: 0.0698\n","[Epoch 46] Loss: 0.1109\n","[Epoch 47] Loss: 0.1450\n","[Epoch 48] Loss: 0.2123\n","[Epoch 49] Loss: 0.1851\n","\n","Best average score: 72.52%\n","Saved: data/vehicles_images/output/prediction_0.png\n","Saved: data/vehicles_images/output/prediction_1.png\n"]}]}]}